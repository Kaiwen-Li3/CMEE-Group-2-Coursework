Starting testing for Booming Bonobos

Note that: 
(1) Major sections begin with a double "====" line 
(2) Subsections begin with a single "====" line 
(3) Code output or text file content are printed within single "*****" lines 

======================================================================
======================================================================
Your current Git repo size is about 2.35 MiB on disk 

PART 1: Checking project workflow...

Found the following directories in root directory of repo: sandbox, results, data, .git, Feedback, code

Found the following files in root directory of repo: .gitkeep, .gitignore, README.md, .DS_Store

Checking for key files in parent directory...

Found .gitignore in parent directory, great! 

Printing contents of .gitignore:

**********************************************************************
*~ 
*.tmp

results/*

**********************************************************************

Found README in parent directory, named: README.md

Printing contents of README.md:

**********************************************************************
# CMEE Biological Computing Bootcamp - Groupwork tasks

This repository contains the coursework of the Computational Methods in Ecology and Evolution (CMEE) module. Our team consists of the following members:

1.Pearce, Saskia   saskia.pearce21@imperial.ac.uk

2.Li, Kaiwen   kaiwen.li21@imperial.ac.uk

3.Li, Yibin    yibin.li24@imperial.ac.uk

4.Zhang, Tianye  tianye.zhang24@imperial.ac.uk


## Brief Description:

This repository contains the group work coursework element for the Computational Methods in Ecology and Evolution (CMEE). The exercises are based on TheMulQuaBio course notes (https://mhasoba.github.io/TheMulQuaBio/intro.html) from the Biological Computing course at the Department of Life Sciences, Imperial College London.

Project Structure and Usage: The repository contains code scripts located in the Code folder. The Data folder includes input files used by some scripts, while the sandbox folder contains experimental files and is not essential to the main coursework. Output files are generated in the results folder for this week’s coursework.

### Project Structure

    Code folder: Contains all scripts.
    Data folder: Includes input files used by scripts.
    Results folder: Stores output files generated by the scripts.
    Sandbox folder: Used for experimental work (not essential for the coursework).

### Languages:

    Linux Shell Scripting 
    Python 
    R version 4.4.0 
    python version 3.9 
    

### Installation:

To clone this repository, use the following command:
bash
git clone git clone git@github.com:Kaiwen-Li3/CMEE-Group-2-Coursework.git 

Project Structure and Usage:
The repository contains 10 primary scripts located in the Code folder. The Data folder includes input files used by some scripts, while the sandbox folder contains experimental files and is not essential to the main coursework. Output files are generated in the results folder for this week’s coursework.

**Overview of the scripts:**


## Oak Species Filtering Script

This script reads a CSV file containing tree species data, identifies species from the **Quercus** genus (oak trees), and writes the filtered results to a separate CSV file. The input file is located in the `../data` directory, and the output will be saved in the `../results` directory. The script is designed to prevent duplicate oak species from appearing in the output.

### Running the Script

**Important:** This script uses relative paths for both input and output files. To ensure the script runs correctly, you **must execute the script from within the `code` folder**. This is necessary because the input data file (`TestOaksData.csv`) is located in the `../data` folder relative to the code, and the results will be saved in the `../results` folder.

## DNA Sequence Alignment Script

This script aligns two DNA sequences, identifies the best alignment based on matching bases, and saves the result. It takes DNA sequences from FASTA files, aligns one sequence against the other at various starting points, calculates an alignment score for each, and determines the alignment with the highest score.
Features

### Functions

    read_fasta: Reads a DNA sequence from a FASTA file, ignoring the header.
    calculate_score: Aligns two sequences from a given start position and computes the score based on matching bases.

### Input

    FASTA files: Two DNA sequences in FASTA format, provided as command-line arguments or default paths (seq1.fasta and seq2.fasta).
        Ensure that the files are in plain text (no .rtf or other extensions).

### Output

    The script writes the best alignment and corresponding score to ../Results/DNA_seq.txt.
    Alignment details, including matching positions, are printed to the terminal.

### Usage

To run the script, use the following format:

bash

python align_seqs_fasta.py <seq1.fasta> <seq2.fasta>

If no files are provided, the script will use default paths.
Example

### Command:

bash

python align_seqs_fasta.py 407228326.fasta 407228412.fasta

Expected Output:

    Terminal display of alignment details with * indicating matching bases and - for mismatches.
    ../Results/DNA_seq.txt file containing the best alignment and score.



/CMEE-Group-2-Coursework/
    └── week3/
        ├── code/
        │   └── oaks_debugme.py
        ├── data/
        │   └── TestOaksData.csv
        └── results/
            └── oaks_debugme_results.csv
           
           
## PP_Regress_Loc.R

### Functions

	Analyses predator-prey mass relationships and visualizes these interactions based on feeding interaction type, predator life stage and location where data was collected	
   
### Input

	EcolArchives-E089-51-D1.csv: Dataset of predator-prey interactions, as well location data.
    
### Output

	key statistics such as slope, intercept, R², p-value, F-statistic, based off feeding interaction type, predator life stage and location iterations. 
    
### Usage

	input EcolArchives-E089-51-D1.csv
    
### Command

	source("PP_Regress_Loc.R")
	
### Expected Output
	
	csv file containing key statistics such as slope, intercept, R², p-value, F-statistic.



## TAutoCorr.R

### Overview

`TAutoCorr.R` is an R script designed to analyze autocorrelation in time-series data. It employs statistical methods to identify and interpret patterns, providing insights into temporal relationships within datasets.

### Features

- Computes autocorrelation functions for time-series data.
- Visualizes autocorrelation using plots.
- Supports various customizable parameters for detailed analysis.

### Requirements

- R (version 4.0 or higher recommended)
- Required packages:
  - **ggplot2**: For data visualization
  - **forecast**: For time-series analysis
  - Other dependencies as specified in the script

### Usage

1. Clone or download the script to your local machine.
2. Ensure the necessary packages are installed in your R environment.
3. Run the script with your time-series dataset. Modify input file paths and parameters as needed in the script.

### Example

```R
# Example usage in R
source("TAutoCorr.R")
# Customize parameters within the script to match your dataset
```

### Input and Output

- **Input**: The script accepts time-series datasets in formats like `.csv` or data frames loaded into R.
- **Output**: Visualizations of autocorrelation and related statistics are generated.

### Notes

- Ensure your input data is properly formatted (e.g., consistent time intervals).
- Refer to inline comments in the script for guidance on parameter adjustments.



## Florida-Group.tex

### Overview

`Florida-Group.tex` is a LaTeX file designed for creating a professional document with embedded images. The images are stored using relative paths, ensuring a well-structured and organized project layout.

### Instructions

1. **Set the Working Directory**:  
   Before running `Florida-Group.tex`, ensure that your working directory is set to the `code` folder. This is crucial as the file uses relative paths to reference images.

2. **Image Locations**:  
   - The images used in the document are located in the `data` folder.
   - File names: `1.png` and `2.png`.

3. **Handling Errors**:  
   - If the images fail to load, verify that the `data` folder is correctly placed in the same directory as the `code` folder.
   - As a fallback, a precompiled PDF version of the document is available in the `code` folder.

### Requirements

- A LaTeX distribution installed on your machine (e.g., TeX Live, MikTeX, Overleaf).
- Ensure that the LaTeX compiler supports `graphicx` for image handling.

### Compilation

To compile `main.tex`:
```bash
pdflatex main.tex
```

Ensure that the terminal or LaTeX editor is set to the `code` folder.


**********************************************************************

======================================================================
======================================================================
PART 2: Checking code and workflow...

======================================================================
Found following files in results directory: PP_Regress_Loc_Results.csv, oaks_debugme_results.csv...

Ideally, Results directory should be empty other than, perhaps a .gitkeep. 

Found 5 code files: PP_Regress_Loc.R, Florida-Group.tex, TAutoCorr.R, align_seqs_fasta.py, oaks_debugme.py

Found the following extra (non-code/script) files: Florida-Group.pdf
======================================================================
Testing script/code files...

======================================================================
Inspecting script file PP_Regress_Loc.R...

File contents are:

**********************************************************************

#setwd("~/Documents/CMEECoursework/WeekFinal/code")

library(dplyr)
library(ggplot2)

rm(list=ls())

#Create dataframe
MyDF <- read.csv("../data/EcolArchives-E089-51-D1.csv")
#dim(MyDF) 
#unique(MyDF$Prey.mass.unit)

#make new prey mass(g) column, where mg is / 1000
MyDF <- MyDF %>%
  mutate(
    Prey.mass.g = ifelse(Prey.mass.unit == "mg", Prey.mass / 1000, Prey.mass)
  )


#Clean up rows with NAs
Clean_data <- MyDF %>%
  group_by(Location, Predator.lifestage, Type.of.feeding.interaction) %>%
  filter(n() > 1, sd(Predator.mass, na.rm = TRUE) > 0) %>%
  ungroup()  # Ungroup to return a clean dataframe





#create regression results from DF
regression_results <- Clean_data %>%
  #group by the 3 fields
  group_by(Location, Predator.lifestage, Type.of.feeding.interaction) %>%
  
  #for each combination, return the intercept, slope, r^2, adjusted r^2 and p_value
  summarize(
    intercept = coef(lm(Prey.mass.g ~ Predator.mass, data = cur_data()))[1],
    slope = coef(lm(Prey.mass.g ~ Predator.mass, data = cur_data()))[2],
    r_squared = summary(lm(Prey.mass.g ~ Predator.mass, data = cur_data()))$r.squared,
    adj_r_squared = summary(lm(Prey.mass.g ~ Predator.mass, data = cur_data()))$adj.r.squared,
    p_value = summary(lm(Prey.mass.g ~ Predator.mass, data = cur_data()))$coefficients[2, 4],
    .groups = "drop"
  )


#Prints and creates CSV file
print(regression_results)
output_file <- "../results/PP_Regress_Loc_Results.csv"
write.csv(regression_results, file = output_file, row.names = FALSE)

#Complete
print(paste("Linear regression results saved to:", output_file))

**********************************************************************

Testing PP_Regress_Loc.R...

Output (only first 500 characters): 


**********************************************************************
# A tibble: 51 × 8
   Location        Predator.lifestage Type.of.feeding.inte…¹ intercept     slope
   <chr>           <chr>              <chr>                      <dbl>     <dbl>
 1 Andaman Sea (W… larva              predacious               1.17e-6  1.24e- 4
 2 Antarctic Peni… larva              planktivorous            1.78e-6  7.30e- 7
 3 Antarctic Peni… larva              predacious               4.78e-8  2.20e- 5
 4 Antarctic Peni… postlarva          piscivorous             -1.73e-2  1.04e
**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***


Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

Warning message:
There was 1 warning in `summarize()`.
ℹ In argument: `intercept = coef(lm(Prey.mass.g ~ Predator.mass, data =
  cur_data()))[1]`.
ℹ In group 1: `Location = "Andaman Sea (West of South Thailand)"`,
  `Predator.lifestage = "larva"`, `Type.of.feeding.interaction = "predacious"`.
Caused by warning:
! `cur_data()` was deprecated in dplyr 1.1.0.
ℹ Please use `pick()` instead. 

======================================================================
Inspecting script file Florida-Group.tex...

File contents are:

**********************************************************************
\documentclass[a4paper,10pt]{article}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[margin=0.8in]{geometry}
\usepackage[compact]{titlesec}

\setlength{\parskip}{0pt}
\setlength{\parindent}{0em}
\renewcommand{\baselinestretch}{0.9}

\begin{document}
\pagestyle{empty}

\section*{\centering Analysis of Key West Annual Mean Temperatures}

\begin{center}
    \textbf{Groupwork Practical: Autocorrelation in Florida Weather} \\
    Group Members: \\
    Zhang, Tianye (\texttt{tianye.zhang24@imperial.ac.uk}) \\
    Li, Yibin (\texttt{yibin.li24@imperial.ac.uk}) \\
    Pearce, Saskia (\texttt{saskia.pearce21@imperial.ac.uk}) \\
    Li, Kaiwen (\texttt{kaiwen.li21@imperial.ac.uk})
\end{center}

\subsection*{Objective and Hypotheses}
The objective is to evaluate whether there is a significant correlation between the mean annual temperatures (\texttt{Temp}) of successive years in Key West using a permutation-based significance test.

\begin{itemize}
    \item \(H_0\): There is no correlation between temperatures of successive years (\texttt{Temp}).
    \item \(H_1\): There is a significant correlation between temperatures of successive years (\texttt{Temp}).
\end{itemize}

\subsection*{Data Overview}
The dataset contains 100 observations of annual mean temperatures (\texttt{Temp}) recorded from 1901 to 2000 in Key West, Florida. The mean temperature is 25.31°C with a standard deviation of 0.495°C.

\subsection*{Methods}
To assess the correlation between successive years:
\begin{enumerate}
    \item The observed Pearson correlation coefficient (\(r_{\text{observed}}\)) between temperatures of successive years was calculated as \(r_{\text{observed}} = 0.326\). The relationship between temperatures of successive years is illustrated in Figure~\ref{fig:scatterplot}.
    
   \begin{figure}[h!]
\centering
\includegraphics[width=0.6\textwidth]{../data/1.png}
\caption{Scatterplot showing the relationship between successive years' temperatures, with a fitted regression line and observed correlation coefficient.}
\label{fig:scatterplot}
\end{figure}
    
    \item A permutation test with \(n_{\text{sim}} = \texttt{10,000}\) iterations was performed by shuffling \texttt{Temp} and recalculating the correlation for each randomly permuted dataset. To ensure reproducibility, the random seed was set using \texttt{set.seed(123)}.
    \item The p-value was computed as:
    \[
    p_{\text{sim}} = \frac{1}{n_{\text{sim}}} \sum_{i=1}^{n_{\text{sim}}} \mathbf{1}\left(|r_{\text{random}, i}| \geq |r_{\text{observed}}|\right),
    \]
    where \(r_{\text{random}, i}\) is the \(i\)-th random correlation, and \(\mathbf{1}\) is the indicator function that equals 1 if the condition is true and 0 otherwise.
\end{enumerate}


As the number of permutations (\(n_{\text{sim}}\)) increases, the empirical p-value (\(p_{\text{sim}}\)) converges to the true p-value (\(p\)) due to the **law of large numbers**. In the code, permutations were tested with \(n_{\text{sim}} = 10\), \(100\), \(1,000\), and \(10,000\), yielding progressively more stable results. For smaller \(n_{\text{sim}}\), the randomness of permutation leads to greater variability in \(p_{\text{sim}}\), while larger \(n_{\text{sim}}\) reduces this variability.

By the **central limit theorem**, the empirical p-value (\(p_{\text{sim}}\)) for a finite number of permutations approximately follows a normal distribution:
\[
p_{\text{sim}} \sim N\left(p, \frac{p(1-p)}{n_{\text{sim}}}\right).
\]
This implies that as \(n_{\text{sim}}\) increases, the variance of \(p_{\text{sim}}\) (\(\text{Var}(p_{\text{sim}})\)) decreases:
\[
\text{Var}(p_{\text{sim}}) = \frac{p(1-p)}{n_{\text{sim}}}.
\]
Thus, the precision of the p-value estimate improves with more permutations, eventually converging to the true p-value (\(p\)). However, diminishing returns are observed beyond a certain point, as further increasing \(n_{\text{sim}}\) provides only marginal gains in accuracy.

\subsection*{Results}
The observed Pearson correlation coefficient between temperatures of successive years was \(r_{\text{observed}} = 0.326\). A permutation test with \(n_{\text{sim}} = 10,000\) yielded a p-value of \(p = 0.001\), indicating that the observed correlation is highly significant.

Figure~\ref{fig:histogram} shows the null distribution of random correlation coefficients. The observed \(r_{\text{observed}} = 0.326\) (red dashed line) lies far in the right tail, demonstrating strong evidence against the null hypothesis (\(H_0\)) of no correlation.


\begin{figure}[h!]
\centering
\includegraphics[width=0.6\textwidth]{../data/2.png}
\caption{Histogram of random correlation coefficients from 10,000 permutations. The red dashed line represents the observed correlation \(r_{\text{observed}} = 0.326\).}
\label{fig:histogram}
\end{figure}

These results provide compelling evidence of a significant temporal dependence in Key West annual temperatures, suggesting that temperature in one year influences that of the following year.

\subsection*{\textbf{Conclusion}}
These results provide compelling evidence of a significant temporal dependence in Key West annual temperatures. The observed correlation coefficient (\(r_{\text{observed}} = 0.326\)) suggests that temperatures in one year are positively correlated with those of the following year. This indicates that temperature dynamics in Key West exhibit a degree of continuity over time, which may reflect underlying climatic patterns or local environmental factors influencing year-to-year variations.

The statistically significant p-value (\(p = 0.001\)) derived from the permutation test strongly rejects the null hypothesis (\(H_0\)) of no correlation, emphasizing that the observed relationship is unlikely to have occurred by random chance. The findings underscore the importance of examining temporal dependencies in climate data to better understand trends and potential long-term impacts.

\end{document}



**********************************************************************

Testing Florida-Group.tex...

======================================================================
Inspecting script file TAutoCorr.R...

File contents are:

**********************************************************************
# Clear workspace
rm(list = ls())

# Load necessary libraries
library(dplyr)
library(ggplot2)
# Load weather data
load("../data/KeyWestAnnualMeanTemperature.RData")

# Plot temperatures over time on line graph
pdf("../results/Temperature-Group.pdf")
plot(ats$Year, 
     ats$Temp, 
     xlab = "Year",
     ylab = "Temperature (°C)",
     type = "l",
     main = "Annual Mean Temperature in Key West, Florida (1901-2000)")
dev.off()

# Create two vectors of temperatures, one with the first row deleted to align for comparison
Temp_t0 <- ats$Temp[2:100]
Temp_t1 <- ats$Temp[1:99]

# Calculate the correlation between successive years
CorCoeff <- cor(Temp_t0, Temp_t1)
cat("Correlation between successive years is", CorCoeff, "\n")

# Create a matrix of 10,000 random permutations of temperature column
set.seed(123)
Temps1 <- replicate(10000, sample(ats$Temp, replace = FALSE))

# For each permutation, realign as before and calculate correlation
RdmCors <- apply(Temps1, 2, function(x) cor(x[2:100], x[1:99]))

# Generate histogram comparing p-values
pdf("../results/Temperature-Group_corr.pdf")
hist(RdmCors, 
     xlim = c(-0.4, 0.4),
     xlab = "Correlation Coefficients",
     main = "Histogram of Random Correlations")
abline(v = CorCoeff, col = "red", lwd = 2, lty = 2)
text(CorCoeff - 0.004, 1500, paste("Correlation coefficient \nfor successive years: ", round(CorCoeff, 3), sep = ""), pos = 2, col = "red", cex = 0.8)
dev.off()

# Combine vectors into a data frame

temp_data <- data.frame(Temp_t1 = Temp_t1, Temp_t0 = Temp_t0)

# Plot temperature correlation between successive and previous years using ggplot2
pdf("../results/Temperature_Correlation.pdf", width = 7, height = 5)
ggplot(temp_data, aes(x = Temp_t1, y = Temp_t0)) +
  geom_point(size = 0.5) +
  geom_smooth(method = "lm", col = "blue") +
  labs(x = "Previous year (degrees)", y = "Successive years (degrees)",
       title = "Temperature Correlation Between Successive and Previous Years") +
  annotate("text", x = min(Temp_t1) + 0.1, y = max(Temp_t0) - 0.2,
           label = paste("Observed correlation coefficient:", round(CorCoeff, 3)),
           color = "red", size = 4, hjust = 0) +
  theme_minimal()
dev.off()


# Calculate estimated p-value (fraction of correlation coefficients more extreme than CorCoeff)
p_estimate <- mean(abs(RdmCors) >= abs(CorCoeff))

# Print p_estimate to screen
cat("P-value estimate is", p_estimate, "\n")
**********************************************************************

Testing TAutoCorr.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***


Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

Error in readChar(con, 5L, useBytes = TRUE) : cannot open the connection
Calls: load -> readChar
In addition: Warning message:
In readChar(con, 5L, useBytes = TRUE) :
  cannot open compressed file '../data/KeyWestAnnualMeanTemperature.RData', probable reason 'No such file or directory'
Execution halted

======================================================================
Inspecting script file align_seqs_fasta.py...

File contents are:

**********************************************************************
"""
Script to align two DNA sequences and find the best alignment based on matching bases.

This script reads two DNA sequences from FASTA files (or defaults to predefined file paths if none are provided),
compares them by aligning one sequence to the other at different starting points, and calculates an alignment score
based on the number of matching bases. The script identifies the best alignment (i.e., the alignment with the highest score)
and writes the result to a file.

Functions:
    - read_fasta: Reads a DNA sequence from a FASTA file, ignoring the header line.
    - calculate_score: Aligns two sequences starting from a specified position and returns the score based on matching bases.

Workflow:
    1. The script reads two DNA sequences from the command line or uses default files.
    2. It identifies the longer sequence and aligns the shorter one at various starting points.
    3. For each alignment, it computes a score based on how many bases match.
    4. It determines the alignment with the highest score and saves the result to an output file.

Input:
    - Two FASTA files containing DNA sequences, passed as command-line arguments or predefined file paths.
      (FASTA files should be in plain text format, without `.rtf` or other extensions.)

Output:
    - The best alignment and corresponding score are written to '../Results/DNA_seq.txt'.
    - Alignment details are printed to the terminal.

Author: Saskia Pearce (sp621@imperial.ac.uk)
Version: 3.9
"""

#input file name and seq1.fasta seq2.fasta 

import sys 
import os

# Define the base directory for your data (relative path)
base_dir = "../data/"

# Checks if commards are provided
if len(sys.argv) >= 3: 
    # Use the paths provided by command-line arguments
    seq1  = os.path.join(base_dir, sys.argv[1])
    seq2  = os.path.join(base_dir, sys.argv[2])
else:
    # Use default paths if no arguments are provided
    seq1  = os.path.join(base_dir, "407228326.fasta")
    seq2  = os.path.join(base_dir, "407228412.fasta")

def read_fasta(filename):
    """
    Read the sequence from the fasta files provided. 
    
    the function returns the sequences in the file to a single string

    Args:
        file name of the fasta file which is being read

    returns: 
        a string containing the concatenated sequence from the fasta file, with new lines removed

    Example: 
    >>> read_fasta("example.fasta")
    'ATGCGTACGTACGATCGACTTTACG'
    
    """ 
    with open(filename, 'r') as f: 
        lines = f.readlines()
    sequence = ''.join([line.strip() for line in lines if not line.startswith(">")])
    return sequence 

seq1 = read_fasta(seq1)
seq2 = read_fasta(seq2)

l1 = len(seq1) #assign longested sequence from file 
l2 = len(seq2) 
if l1 >= l2:
    s1 = seq1
    s2 = seq2
else:
    s1 = seq2
    s2 = seq1
    l1, l2 = l2, l1 # swap the two lengths

# A function that computes a score by returning the number of matches starting
# from arbitrary startpoint (chosen by user)
def calculate_score(s1, s2, l1, l2, startpoint):
    """
    Calculate the alignment score between two DNA sequences starting from a specified position.

    This function aligns a portion of sequence `s2` with sequence `s1` starting at the given 
    `startpoint`. It compares the bases of both sequences, adds to the score if they match, 
    and prints the alignment visually with '*' indicating a match and '-' indicating a mismatch.

    Args:
        s1 (str): The first DNA sequence (usually the longer one).
        s2 (str): The second DNA sequence (usually the shorter one to be aligned with `s1`).
        l1 (int): The length of sequence `s1`.
        l2 (int): The length of sequence `s2`.
        startpoint (int): The starting position in `s1` where the alignment with `s2` begins.

    Returns:
        int: The alignment score representing the number of matching bases between `s1` and `s2`.

    Example:
        >>> calculate_score("AGCTGAC", "GCT", 7, 3, 1)
        .***
        .GCT
        AGCTGAC
        3
    """
    matched = "" # to hold string displaying alignements
    score = 0
    for i in range(l2):
        if (i + startpoint) < l1:
            if s1[i + startpoint] == s2[i]: # if the bases match
                matched = matched + "*"
                score = score + 1
            else:
                matched = matched + "-"

    # some formatted output
    print("." * startpoint + matched)      #startpoitn has to shift up every time       
    print("." * startpoint + s2)
    print(s1)
    print(score) 
    print(" ")

    return score

# Test the function with some example starting points:
# calculate_score(s1, s2, l1, l2, 0)
# calculate_score(s1, s2, l1, l2, 1)
# calculate_score(s1, s2, l1, l2, 5)

my_best_align = None
my_best_score = -1

with open('../Results/DNA_seq.txt', 'w') as f:
    for i in range(l1):
        score = calculate_score(s1, s2, l1, l2, i)
        if score > my_best_score:
            my_best_align = "." * i + s2
            my_best_score = score
    f.write("Best alignment:\n")
    f.write(f"{my_best_align}\n{s1}\n")
    f.write(f"Best score: {my_best_score}\n")

print(my_best_align)
print(s1)
print("Best score:", my_best_score)




#results = '../results/alignment_results.txt'

# now try to find the best match (highest score) for the two sequences
#my_best_align = None
#my_best_score = -1 #alignment will always be higher than this starting score

#f = open('../Results/DNA_seq.txt','w')
#for i in range(l1): # Note that you just take the last alignment with the highest score
    #z = calculate_score(s1, s2, l1, l2, i) #arguement in the file 
    #if z > my_best_score:
        #my_best_align = "." * i + s2 # think about what this is doing!
        #my_best_score = z 
        #f.write("Best alignment:\n")
        #f.write(f"{my_best_align}\n{s1}\n")
        #f.write(f"Best score: {my_best_score}\n")

#f.close()

#print(my_best_align)
#print(s1)
#print("Best score:", my_best_score) # best score printed

# assigning seq1.fasta (first argument)






# assigning seq2.fasta (second arguement)



**********************************************************************

Testing align_seqs_fasta.py...

align_seqs_fasta.py is a Python script file;

checking for docstrings...

Found one or more docstrings and functions

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error (or warning):

***IGNORE IF THIS ERROR IS EXPECTED AS PART OF AN IN-CLASS EXERCISE***

Traceback (most recent call last):
  File "/home/mhasoba/Documents/Teaching/IC_CMEE/2024-25/Coursework/StudentRepos/BoomingBonobos_na/code/align_seqs_fasta.py", line 138, in <module>
    with open('../Results/DNA_seq.txt', 'w') as f:
FileNotFoundError: [Errno 2] No such file or directory: '../Results/DNA_seq.txt'

======================================================================
Inspecting script file oaks_debugme.py...

File contents are:

**********************************************************************
"""
This module processes a CSV file of tree species, checks whether each species belongs to the 'Quercus' genus (oak trees),
and writes the oak species to an output CSV file, while filtering out duplicate entries.

Functions:
    - is_an_oak(name): Determines if a species belongs to the Quercus genus (oak trees).
    - main(argv): Reads input CSV data, processes the species list, and writes oaks to the results file.
    
Module-Level:
    The script performs the following tasks:
    1. Reads a CSV file ('../data/TestOaksData.csv') containing tree species data with 'Genus' and 'Species' columns.
    2. Identifies oak species (those from the 'Quercus' genus) and writes them into a new CSV file ('../results/oaks_debugme_results.csv').
    3. Ensures there are no duplicate oak species in the output.
    4. Handles both the presence and absence of headers in the input file.

    The script also includes unit tests within the `is_an_oak` function, which can be executed via Python's doctest module.

Usage:
    Run the script from the command line or from within another Python program.
    Example:
        $ python oaks_debugme.py
"""

import csv
import sys
import doctest

#==================================================================================================

# Define the function `is_an_oak`
def is_an_oak(name):
    """
    Determines if a tree species belongs to the Quercus genus (oak trees).
    
    Args:
        name (str): The name of the genus to check (usually the genus of a tree).
    
    Returns:
        bool: True if the species belongs to the Quercus genus, otherwise False.
    
    This function converts the input string to lowercase, checks if the name starts with 'quercus', and ensures
    that either the name exactly matches 'quercus' or the next character after 'quercus' is a space.
    
    Examples:
        >>> is_an_oak('Fagus sylvatica')
        False
        >>> is_an_oak('Quercus robur')
        True
        >>> is_an_oak('quercus ROBUR')
        True
        >>> is_an_oak('Quercuss robur')
        False
        >>> is_an_oak('Quercus')
        True
        >>> is_an_oak(' Quercus robur')
        False
    """
    # Convert the name to lowercase for case-insensitive matching
    name = name.lower()
    # Check if the name starts with 'quercus' and either matches exactly or has a space after 'quercus'
    return name.startswith('quercus') and (len(name) == len('quercus') or name[len('quercus')] == ' ')

#==================================================================================================

def main(argv):
    """
    Main function that processes a CSV file containing genus and species data, identifies oak species,
    and writes the results to an output CSV file.
    
    Args:
        argv (list): Command line arguments passed to the script (though not used directly in this implementation).
    
    Steps:
        1. Reads the input CSV file ('../data/TestOaksData.csv') containing tree species information.
        2. Identifies species that belong to the Quercus genus using the `is_an_oak` function.
        3. Writes oak species into the output file ('../results/oaks_debugme_results.csv'), avoiding duplicates.
        4. Handles input files with or without headers. If headers exist, they are written to the output.

    Input:
        The input CSV file should have two columns: 'Genus' and 'Species'.
    
    Output:
        The results CSV file will contain oak species filtered by genus and species.

    Returns:
        int: Status code (0 if successful).
    
    Example usage:
        $ python oaks_debugme.py
    
    Notes:
        - The input file '../data/TestOaksData.csv' is expected to exist and be properly formatted.
        - This function handles duplicates and only outputs unique oak species.
    """
    # Open the input CSV file with tree species data and prepare to write results to another CSV file
    f = open('../data/TestOaksData.csv', 'r')  # Input file
    g = open('../results/oaks_debugme_results.csv', 'w')  # Output file
    taxa = csv.reader(f)  # Read the input file
    csvwrite = csv.writer(g)  # Prepare to write to the output file
    oaks = set()  # Set to store unique oak species names

    # Skip the first row (header), if present, and write it to the output file
    header = next(taxa)
    if header[0].strip().lower() == 'genus' and header[1].strip().lower() == 'species':
        print("Skipping header row...")  # Inform that the header row is being skipped
        csvwrite.writerow(header)  # Write the header to the output file
    else:
        taxa = [header] + list(taxa)  # If no header row, add it back to the remaining rows
        header = ["Genus", "Species"]
        csvwrite.writerow(header)  # Write default header row

    # Iterate over each row and check if it belongs to the Quercus genus (oak trees)
    for row in taxa:
        print(row)
        print("The genus is: ", row[0])

        # If it's an oak, and not a duplicate, write it to the results file
        if is_an_oak(row[0]):
            rowfullname = row[0] + " " + row[1]
            if rowfullname not in oaks:  # Prevent duplicates
                print(rowfullname, " is an oak! \n")
                csvwrite.writerow([row[0], row[1]])  # Write the row to the results file
                oaks.add(rowfullname)  # Add the oak species to the set
        else:
            rowfullname = row[0] + " " + row[1]
            print(rowfullname, "is not an oak! \n")  # If not an oak, display message and skip

    return 0  # Return 0 to indicate successful execution

#==================================================================================================

if __name__ == "__main__":
    """
    Calls the main function and runs the doctest module to test the is_an_oak function.
    The script will exit with status code 0 upon successful execution.
    """
    import doctest
    doctest.testmod()  # Run doctests to validate the is_an_oak function
    status = main(sys.argv)  # Run the main function
    sys.exit(status)  # Exit the program with the returned status













**********************************************************************

Testing oaks_debugme.py...

oaks_debugme.py is a Python script file;

checking for docstrings...

Found one or more docstrings and functions

Output (only first 500 characters): 


**********************************************************************
Skipping header row...
['Quercus', ' robur']
The genus is:  Quercus
Quercus  robur  is an oak! 

['Fraxinus', ' excelsior']
The genus is:  Fraxinus
Fraxinus  excelsior is not an oak! 

['Pinus', ' sylvestris']
The genus is:  Pinus
Pinus  sylvestris is not an oak! 

['Quercus', ' cerris']
The genus is:  Quercus
Quercus  cerris  is an oak! 

['Quercus', ' petraea']
The genus is:  Quercus
Quercus  petraea  is an oak! 


**********************************************************************

Code ran without errors

Time consumed = 0.03771s

======================================================================
======================================================================
Finished running scripts

Ran into 3 errors

======================================================================
======================================================================
Finally, checking git log:

commit 478025e2f916ca04089c732d05d2dc8766ab7834
Author: Yibin.Li <yl2524@ic.ac.uk>
Date:   Fri Dec 6 16:32:22 2024 +0000

    Delete code/README.md

commit b60d41dcc9235e0843f5a58a4147ab97dee8421f
Author: Yibin.Li <yl2524@ic.ac.uk>
Date:   Fri Dec 6 16:26:50 2024 +0000

    Update README.md

commit 0e37665862a30a8c2af0fbdbf9a6a8f177ca127b
Author: Yibin.Li <yl2524@ic.ac.uk>
Date:   Fri Dec 6 16:25:08 2024 +0000

    Update README.md

commit 31accf0a5ea0b9182f08eb4672f850b671f468e9
Author: Yibin.Li <yl2524@ic.ac.uk>
Date:   Fri Dec 6 16:23:49 2024 +0000

    Update README.md

commit 08109aeac056815e72e3db20261b9667c287ae84
Author: Yibin.Li <yl2524@ic.ac.uk>
Date:   Fri Dec 6 16:23:06 2024 +0000

    Update README.md

commit 1d56a6134e9818b5c36dcdd440aeffbb911d0ca5
Author: Yibin.Li <yl2524@ic.ac.uk>
Date:   Fri Dec 6 16:22:04 2024 +0000

    Update README.md

commit 5b8cd740bbb1beb56dd98338f42b2658b6266ae2
Author: Yibin.Li <yl2524@ic.ac.uk>
Date:   Fri Dec 6 16:21:10 2024 +0000

    Update README.md

commit 0177783bce9a16116bd104dddfaa0fb69ef4441d
Author: Yibin.Li <yl2524@ic.ac.uk>
Date:   Fri Dec 6 16:19:54 2024 +0000

    Update README.md

commit bde6e10f2c891ed6e734efe215b5ce529a02a1ae
Author: Yibin.Li <yl2524@ic.ac.uk>
Date:   Fri Dec 6 16:18:53 2024 +0000

    Update README.md

commit b1ddaf86ab7d669dd613c1b6cee125e62bb458f7
Author: Yibin.Li <yl2524@ic.ac.uk>
Date:   Fri Dec 6 16:17:25 2024 +0000

    Update README.md

commit 8e0224639c5dcb9e8a67be7b86f59118bc905549
Author: Yibin.Li <yl2524@ic.ac.uk>
Date:   Fri Dec 6 16:16:03 2024 +0000

    Update README.md

commit d3656b96d210c8d012d44b3324a406d56f561d96
Author: Yibin.Li <yl2524@ic.ac.uk>
Date:   Fri Dec 6 16:11:20 2024 +0000

    Update README.md

commit 1dd6c209f873f341ae3ed3bf3209b94a28b41c88
Author: Yibin.Li <yl2524@ic.ac.uk>
Date:   Fri Dec 6 16:08:27 2024 +0000

    Update README.md

commit 7650295cf38e7d68f1e0123fd94443318146eef6
Author: Yibin.Li <yl2524@ic.ac.uk>
Date:   Fri Dec 6 16:05:37 2024 +0000

    Update

commit 14df976719e4a9b6d0bf47f1faca2926d0ef5ca8
Author: Yibin.Li <yl2524@ic.ac.uk>
Date:   Fri Dec 6 16:05:18 2024 +0000

    Update

commit 66a452c4a87992a9e79cf71d5a9022911e2b14f3
Author: Yibin.Li <yl2524@ic.ac.uk>
Date:   Fri Dec 6 13:55:14 2024 +0000

    Update

commit dbe796b14e84ef83388e07ab554c861ed7b87a84
Merge: 2c46d7b e3c26b5
Author: Zhang Tianye <tz124@ic.ac.uk>
Date:   Fri Dec 6 13:51:38 2024 +0000

    Merge remote-tracking branch 'origin/master'

commit 2c46d7bf8dc2105c95d0d0f7f8441e4b1daabe33
Author: Zhang Tianye <tz124@ic.ac.uk>
Date:   Fri Dec 6 13:51:25 2024 +0000

    readme update

commit e3c26b5deeb474f04f076bc702a96d39ecb37cde
Author: Yibin.Li <yl2524@ic.ac.uk>
Date:   Fri Dec 6 13:45:10 2024 +0000

    Update

commit 87b180d0dfab6eb3dadb97efe9af53dd3cd6487c
Author: Yibin.Li <yl2524@ic.ac.uk>
Date:   Fri Dec 6 13:42:49 2024 +0000

    Update

commit 88d3f55202d9799afb6bf0b6a8c5beb396d8cf37
Merge: ef09111 68312b9
Author: Kaiwen Li <kaiwen.li21@imperial.ac.uk>
Date:   Fri Dec 6 05:32:33 2024 +0000

    Merge branch 'Kaiwen_Regression_Code'

commit ef09111c6fb9307a244b39680e527ca1949ce095
Merge: f1de76d 9f926b5
Author: Kaiwen Li <kaiwen.li21@imperial.ac.uk>
Date:   Fri Dec 6 05:22:07 2024 +0000

    The great merger

commit f1de76d0beb38a960a1b00c61302db4981bc9902
Merge: d1bec50 7c5ec64
Author: Kaiwen Li <kaiwen.li21@imperial.ac.uk>
Date:   Fri Dec 6 05:16:23 2024 +0000

    Merging branches into master

commit 68312b9706654c8c453e98f2f8b57ada9c101916
Author: Kaiwen Li <kaiwen.li21@imperial.ac.uk>
Date:   Fri Dec 6 05:10:50 2024 +0000

    Final

commit 7c5ec6435ae845ef222fa4ea1f9bada3cb693883
Author: Yibin.Li <yl2524@ic.ac.uk>
Date:   Wed Dec 4 23:31:00 2024 +0000

    week4

commit d1bec50373d1139ae72f20ff88e624d209555053
Author: Zhang Tianye <tz124@ic.ac.uk>
Date:   Wed Dec 4 23:19:54 2024 +0000

    Report PDF Version

commit 4cc1c33a5d3c3499147233ce575ac46ff9cf5e78
Author: zhangtianyedue <zhangtianyedue@gmail.com>
Date:   Wed Dec 4 23:14:46 2024 +0000

    Latex2png

commit 0aabd7c5c7c751c02efec6fecf17fd4025b0ac20
Author: zhangtianyedue <zhangtianyedue@gmail.com>
Date:   Wed Dec 4 23:14:17 2024 +0000

    Latex1png

commit 74f87378f2935c8702a322b81431a0ca42d09db2
Author: zhangtianyedue <zhangtianyedue@gmail.com>
Date:   Wed Dec 4 23:12:55 2024 +0000

    week4Latex

commit 9f926b5d6405813e955af0aa014a80c7c1986a12
Author: Saskia <Saskiapearce@yahoo.com>
Date:   Wed Dec 4 20:45:17 2024 +0000

    readme file reformatting

commit 668047a5c4ca4a84fc78adce9785b8c9028c73a0
Author: Saskia <Saskiapearce@yahoo.com>
Date:   Wed Dec 4 20:31:19 2024 +0000

    Updated readme file (regress_loc)

commit 1baffe5ac7eed4eb75fd7302bd914e4c06cfb99e
Author: Saskia <Saskiapearce@yahoo.com>
Date:   Wed Dec 4 20:27:07 2024 +0000

    Updated code readme file (regress_loc)

commit 28dd18defe39f5fa2fd3a731ff61c443bb4cca39
Author: Saskia <Saskiapearce@yahoo.com>
Date:   Wed Dec 4 20:31:19 2024 +0000

    Updated readme file (regress_loc)

commit 92be845ce063a789c9ed896132fe94ac9ff6cc57
Author: Saskia <Saskiapearce@yahoo.com>
Date:   Wed Dec 4 20:27:07 2024 +0000

    Updated code readme file (regress_loc)

commit 974450dea48beb9d94d72f23688c5d3cd6090a09
Author: Saskia <Saskiapearce@yahoo.com>
Date:   Wed Dec 4 20:07:38 2024 +0000

    Updated readme file (regress_loc)

commit 5132ca4a7da8128a2a4f76abf3400f56f7e26593
Author: Kaiwen Li <kaiwen.li21@imperial.ac.uk>
Date:   Wed Dec 4 14:52:33 2024 +0000

    Deleted random .swp file

commit 2779d6e129e64350585cb7efea4fe1bec5133d66
Author: Kaiwen Li <kaiwen.li21@imperial.ac.uk>
Date:   Wed Dec 4 14:52:00 2024 +0000

    Edited

commit c7a7119b887b050744cb7daadd27ac952cb4fe50
Author: Kaiwen Li <kaiwen.li21@imperial.ac.uk>
Date:   Wed Dec 4 14:51:14 2024 +0000

    Edited

commit 371cadaf01550846f69aa4f3574b06160e1d765b
Author: Kaiwen Li <kaiwen.li21@imperial.ac.uk>
Date:   Wed Dec 4 14:48:59 2024 +0000

    Delete

commit 38432f34bd7d9c936d5e593ae5d7b0bc1671cedd
Author: Kaiwen Li <kaiwen.li21@imperial.ac.uk>
Date:   Wed Dec 4 14:39:33 2024 +0000

    Added data

commit d3c5c568ff15175e5ebd66bec98b528189eb34b6
Author: Kaiwen Li <kaiwen.li21@imperial.ac.uk>
Date:   Wed Dec 4 14:32:33 2024 +0000

    Added PP_Regress_Loc

commit a1ee9a0cb5f38a3999dba36584a8f2950cd91bf6
Author: Saskia <Saskiapearce@yahoo.com>
Date:   Fri Oct 25 11:53:07 2024 +0100

    Remove .DS_Store from tracking and add to .gitignore

commit aa281256cbb4cb2e541e25a68d4c2941aeb273e0
Author: Saskia <Saskiapearce@yahoo.com>
Date:   Fri Oct 25 10:55:33 2024 +0100

    readme file

commit bdb9ef1c2cefde2c7f42038b927cf2ea05875afd
Author: Zhang Tianye <tz124@ic.ac.uk>
Date:   Thu Oct 24 15:45:55 2024 +0100

    Readme.de parent file update
    
    add the Rdm for parent file

commit a9ef8eede4500b85ae15dd287e3d1c45482e84de
Author: Zhang Tianye <tz124@ic.ac.uk>
Date:   Thu Oct 24 15:31:28 2024 +0100

    Docstring to oaks
    
    add the Doctring to the second task

commit 60680b99c4bd98a409707bce4e52b91c513fa1bd
Merge: 12ffe1e 5aac5dc
Author: Kaiwen Li <kaiwen.li21@imperial.ac.uk>
Date:   Thu Oct 24 14:36:49 2024 +0100

    Added doctests to oaks

commit 5aac5dc05af38abc7403793c1e9a3447d0b427d2
Merge: f3c6fa8 f9c5280
Author: Saskia <Saskiapearce@yahoo.com>
Date:   Thu Oct 24 10:35:21 2024 +0100

    Resolved conflict with code/align_seqs_fasta.py

commit 12ffe1ef18c10b34a48fa2ebd77461173d6c6737
Author: Kaiwen Li <kaiwen.li21@imperial.ac.uk>
Date:   Thu Oct 24 10:31:50 2024 +0100

    Added docstrings to oaks

commit f3c6fa80631f89eea81eda0e4d1367199e7ace0b
Author: Saskia <Saskiapearce@yahoo.com>
Date:   Thu Oct 24 10:07:34 2024 +0100

    Week 1

commit f9c528098fad9bbe47a51193c368e6515434d614
Author: Yibin.Li <yl2524@ic.ac.uk>
Date:   Wed Oct 23 23:37:28 2024 +0100

    Delete data/407228412.fasta

commit 5a86893942f27218b0e28ce4c48d3dfc22d96b06
Author: Yibin.Li <yl2524@ic.ac.uk>
Date:   Wed Oct 23 23:37:19 2024 +0100

    Delete data/407228326.fasta

commit f1f88eeada8600ba1ec514c5d6eb388720de156d
Author: Yibin.Li <yl2524@ic.ac.uk>
Date:   Wed Oct 23 23:35:36 2024 +0100

    Align DNA sequences

commit 8cd4d2fa8856c5bf6817aba684444a9c06d8e718
Author: Zhang Tianye <tz124@ic.ac.uk>
Date:   Wed Oct 23 22:03:46 2024 +0100

    modify readme.md

commit 93c372b47529bc8bccabf2499f1caa387abcd7a4
Author: Zhang Tianye <tz124@ic.ac.uk>
Date:   Wed Oct 23 21:51:22 2024 +0100

    Readme.md of missing oaks problems

commit a581707ce940461e9d77f619723713edf10d26c4
Merge: 04239c9 8260593
Author: Kaiwen Li <kaiwen.li21@imperial.ac.uk>
Date:   Wed Oct 23 11:52:39 2024 +0100

    Merge branch 'Kaiwen'

commit 04239c9125836aceb08db78f10bc27dd1f84e196
Author: Yibin.Li <yl2524@ic.ac.uk>
Date:   Wed Oct 23 11:15:33 2024 +0100

    Delete code/align_seqs_fasta.Yibin.Li.py

commit 5e21413ac1b22931d2970020288b062678ce9e56
Author: Yibin.Li <yl2524@ic.ac.uk>
Date:   Wed Oct 23 11:09:08 2024 +0100

    Delete code/align_seqs_fasta.py

commit 046c31c763952b3e6ca34211a50b0c7f241514d6
Author: Yibin.Li <yl2524@ic.ac.uk>
Date:   Wed Oct 23 11:04:06 2024 +0100

    Add files via upload

commit 82605930f18294e3dc3f22d6ca7eb4105d6fb179
Author: Kaiwen Li <kaiwen.li21@imperial.ac.uk>
Date:   Wed Oct 23 11:03:08 2024 +0100

    Gitignore now ignores results files

commit a0a31a792ffd9b05f82fc008218ce94b2ec42279
Author: Saskia <Saskiapearce@yahoo.com>
Date:   Wed Oct 23 11:01:05 2024 +0100

    Fasta seq

commit ff3cf303b6138ce41e95babebfe78064f903117c
Author: Yibin.Li <yl2524@ic.ac.uk>
Date:   Wed Oct 23 11:00:17 2024 +0100

    Add files via upload

commit bfb90dcba7f8fe6c007c5366c27c721f1cf16f25
Author: Kaiwen Li <kaiwen.li21@imperial.ac.uk>
Date:   Wed Oct 23 10:58:25 2024 +0100

    Missing oaks problem

commit cdedaeac9e0be4b81d9cafc7f468ba839a3fb8ea
Author: Saskia <Saskiapearce@yahoo.com>
Date:   Wed Oct 23 10:53:25 2024 +0100

    Align_seq_fasta

commit 3f264b39ad0b026b92cd67771fe935ab101920ad
Author: Kaiwen Li <kaiwen.li21@imperial.ac.uk>
Date:   Tue Oct 22 14:23:08 2024 +0100

    Added folders, gitkeep, gitignore

commit ffde0c9b45aca885e52ce46e4602c8640d78e441
Author: Kaiwen Li <kaiwen.li21@imperial.ac.uk>
Date:   Tue Oct 22 14:15:42 2024 +0100

    Added README.md file

FINISHED LOGGING

